---
title: "TSE Assignment 2"
author: "Maximilian J. Arrich"
date: "29 4 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(tidyverse)
library(pander)

```


## 1. ETF Data Analysis
(a) Use the R “quantmod” library to draw the backward-adjusted closing prices of the ETFs with ticker symbols EWA and EWC from 2012-02-02 to 2020-02-02. These two ETFs represent two equity baskets, the MSCI Australia and the MSCI Canada. Plot the two time series in one plot and comment.

```{r, include=TRUE, message = FALSE, warning = FALSE}
library(quantmod)

# Load the data from quantmod
getSymbols("EWA",src="yahoo")
getSymbols("EWC",src="yahoo")

# clean up
ewa <- EWA %>% .[,6] %>% window(start = "2012-02-02", end = "2020-02-02") %>% 
  set_colnames("EWA") %>% as_tibble(rownames = "time")
ewc <- EWC %>% .[,6] %>% window(start = "2012-02-02", end = "2020-02-02")  %>% 
  set_colnames("EWC")%>% as_tibble(rownames = "time")
data <- full_join(ewa, ewc, by = "time") %>% mutate(time = as.Date(time))

# reshape and plot
data %>% pivot_longer(-time, "Series") %>% 
  ggplot(aes(x = time, y = value, color = Series)) + geom_line() + 
  ylab("Adj. Closing Price") + xlab("Time")

```

The two series seem to be heavily positively correlated.Furthermore, both series show a positive trend which leads to the impression of both series not being stationary. However the two series appear to be co-stationary.


(b) Calculate the spread of the two times series, plot it and calculate ACF and PACF. Comment. Name two ARIMA(p,d,q) models that could suit the data according to the plots.

```{r, include=TRUE, message = FALSE, warning = FALSE}
data <- data %>% mutate(spread = EWA - EWC) 
data %>% ggplot(aes(x = time, y = spread)) + geom_line(color = "blue", alpha = 0.6) +
  ylab("Adj. Closing Price") + xlab("Time") + ggtitle("Spread")

```
COntrary to the two series individually, the spread seems to be stationary. This is a furhter hint to costationarity of the two series.


```{r, include=TRUE, message = FALSE, warning = FALSE}
acf(data$spread)
```

The spread shows strong autocorrelation. 


```{r, include=TRUE, message = FALSE, warning = FALSE}
pacf(data$spread)
```

The spread shows some significant partial autocorrelation. This hints to the existance of 



(c) Conduct an Augmented Dickey Fuller test on all three time series using the R library “urca”. Explain which set-up you choose in the testing procedure (lag length and regression setting) using economic and econometric arguments. Comment on the results.

```{r, include=TRUE, message = FALSE, warning = FALSE}
library(urca)
library(broom)


adf_res <- data %>% select(-time) %>% 
  imap(~ur.df(.x, lag = 5, type = "none", selectlags = "AIC")@testreg %>% tidy() %>% filter(!grepl("diff", term)) %>% mutate(series = .y)) %>%
  do.call(what = bind_rows) %>% select(series, statistic, p.value)

pander(adf_res)

```

We can not reject a unit root for any of the series.



(d) What kind of econometric relationship do the EWA and EWC series adhere to? Explain in a few words the Johansen test. Conduct a Johansen test (command “ca.jo” in the “urca” library) and comment on your results.
```{r, include=TRUE, message = FALSE, warning = FALSE}
library(urca)
library(broom)

ca.jo(data %>% select(EWA, EWC))



```

## 2. Seasonalities and Forecasting

(a) The title "InternetRetailSales.xlsx" contains information on monthly average in-
ternet retail sales in the UK from July 2011 to December 2019 by the British
Offce for National Statistics. Load the file into R and turn the data into a time
series object using the "tseries" library. Plot the data and comment.

```{r, include=TRUE, message = FALSE, warning = FALSE}
# Read data and convert date column to comfortable format
data <- read_csv2("./data/InternetRetailSales.csv") %>% 
  unite(col = "date", Year:Month, sep = " ", remove = FALSE) %>% 
  mutate_at("date", ~ymd(., truncated = 1))

# Plot the data
plot(ts_data)
ggplot(data, aes(x = date, y = InternetRetail)) + 
  geom_line() +
  theme_hc()

```
From the plot we can observe that the sales are trending upwards.
Additionally, we observe sales to be highly seasonal, with a sharp spike
in the last quarter and an increase in magnitude over time. 


(b) Create a seasonal plot of the data (you can e.g. use the function "ggseasonplot",
choose the frequency appropriately) and plot the ACF of the time series for a
number of h = 36 lags. Comment.

```{r, include=TRUE, message = FALSE, warning = FALSE}
# Convert data to time series object
ts_data <- ts(data$InternetRetail, frequency = 12, start = c(2011, 7))

# Create seasonal plot
ggseasonplot(ts_data,
             season.labels = TRUE,
             year.labels=TRUE,
             year.labels.left=TRUE) + 
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Internet Retail Sales",
       subtitle = "Monthly Average Internet Retail Sales in the UK (July 2011-Dec 2019)",
       x = "Month",
       y = "Internet Retail Sales")+
  theme(legend.position = "none")+
  guides(color=guide_legend(NULL))+
  theme_hc()

```
With this plot the time axis is fixed to one year and different
years are represented by different lines. We can thus better compare sales
across years and more clearly see how sales spike in november and december, 
due to christmas business. Black friday sales could also be considered as source for the increase.

```{r, include=TRUE, message = FALSE, warning = FALSE}

# Create acf plot
acf(ts_data, lag.max = 36)

```
 The acf shows how much the sales of one month correlate with the nth lag of monthly sales, up to 36 months. We can see that the correlation is especially high between the holiday sale seasons, which are 12 months apart. The acf is significant up to a lag of 24, resembling a 2 year time 
period.

(c) Calculate the trend using a moving average with a window of twelve observations.
Add it to your plot and comment shortly.

```{r, include=TRUE, message = FALSE, warning = FALSE}

data$ma <- ma(ts_data, order = 12, centre = TRUE)

# Plot the data accordingly
ggplot(data, aes(x = date)) + 
  geom_line(aes(y = InternetRetail)) +
  geom_line(aes(y = simple_ma), color = "red") +
  scale_x_date(date_breaks = "12 months",
               date_labels = "%m/%y")+
  labs(title = "Sales and MA(12) Trend",
       subtitle = "Monthly Average Internet Retail Sales",
       x = "Date",
       y = "Sales")
theme_hc()

```
The moving average slides a window of fixed size over the data and them computes the mean of them. It takes the following form 
$$\hat{T}_t = \frac{1}{m} \sum^k_{j = -k}y_{t+j}$$ with $k = \frac{m-1}{2}$.
The order 


(d) Explain the difference between an additive and a multiplicative time series de-
composition into seasonal, trend and residual component. Justify which decom-
position to choose for the data set.

The type of the time series determines how the trend, seasonal and residual comp
onent interact. If the time series is multiplicative, the components multiply
together. An increasing trend then results in an increased amplitude of the
seasonal activity. It takes the following form:
$$y_t = m_ts_t  e_t$$
where $m_t$ is the trend component, $s_t$ is the seasonal component and $e_t$ the residual component.
The additive time series is defined by an additive nature of the individual comp
onents. An increasing trend then does not corresponds to increasing peaks and troughs
of the time series. It stays relatively stable and no change in amplitude can
be observed.
$$y_t = m_t + s_t + e_t$$
For this dataset a multiplicative decomposition should be chosen, since we clearly
see an increase in the fluctuation with increasing trend. 

```{r, include=TRUE, message = FALSE, warning = FALSE}
# Add simple moving average with window starting for t-6
data$ma <- ma(ts_data, order = 12, centre = TRUE)

# Plot the data accordingly
ggplot(data, aes(x = date)) + 
  geom_line(aes(y = InternetRetail)) +
  geom_line(aes(y = simple_ma), color = "red") +
  theme_hc()

```
The MA process is of order 12, and thus averages over one year.
We can clearly see the smooth upwards trend of sales. 

(e) Detrend the time series according to your decomposition choice (either multiplica-
tive or additive). Would you deem the resulting series to be (weakly) stationary?

```{r, include=TRUE, message = FALSE, warning = FALSE}
data <- data %>% mutate(detrend = InternetRetail/simple_ma)
ggplot(data, aes(x = date)) + 
  geom_line(aes(y = detrend)) +
    labs(title = "Trend Component",
       x = "Time",
       y = "Value")
  theme_hc()


```
No, the detrended data is not weakly stationary since the graph is obviously a 
function of time and seasonal patterns pertain. Both mean and variance of the
time series are a function of time. 



```{r, include=TRUE, message = FALSE, warning = FALSE}

seasonal_component <- data %>% 
  group_by(Month) %>% 
  summarize(s_t = mean(m_t)) %>% 
  mutate(Month = month(mdy(Month, truncated = 2), label = T, locale = "eng")) %>% 
  arrange(Month)

# Plot residual
data <- data %>% right_join(., seasonal_component, by = "Month") %>% 
  mutate(u_t = InternetRetail / (ma * s_t))

data %>% ggplot(aes(x=date, y = u_t)) + 
  geom_line() + 
  theme_hc()

```
The seasonal component can also be considered as stationary process, since it 
Clearly, the error term is white noise, hence the process can be seen as weakly stationary.

(f) Decompose the time series using the "decompose" command and comment.

```{r, include=TRUE, message = FALSE, warning = FALSE}

dec_data <- decompose(ts_data, type = "multiplicative")
plot(dec_data)

```

The process is again decomposed into the trend, seasonal and random component.
The trend is smooth and continuously rising. The random seems to be 
a stationary process with constant mean and variance. The seasonal component..(stationary?)

(g) Investigate the ACF of the residual component of the decomposition. Are they
white noise?

```{r, include=TRUE, message = FALSE, warning = FALSE}

dec_data$random %>% acf(na.action = na.pass)

```

The residual component of the decomposition, seem to be white noise
as the spikes of the acf are only rarely significant.


(h) Fit an ARIMA model using the "auto.arima" command of the "forecast" library.
Check the model diagnostics.

```{r, include=TRUE, message = FALSE, warning = FALSE}
arima <- data$InternetRetail %>% auto.arima
summary(arima)

```
An ARIMA(2,1,3) was applied to the data. An intercept is also included to account for the drift.

The model and the RMSE has low error measures suggesting a good fit to the data.

(i) Calculate h = 24 step ahead forecasts for the time series using the function "fore-
cast" of the library "forecast". Does your forecast live up to your expectations?


```{r, include=TRUE, message = FALSE, warning = FALSE}
preds <- forecast(arima, h = 24)
preds

```



